{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN73fWUp5Zh371JE0wXYQ7X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valeromora/TAM_2025-1/blob/main/Parcial2/Dashboard_Parcial2_TAM_2025_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dashboard Interactivo - Parcial 2 TAM 2025-1\n",
        "\n",
        "Este dashboard tiene como objetivo ilustrar de forma **interactiva y visual** los principales conceptos y resultados obtenidos en el desarrollo del taller de Teor√≠a de Aprendizaje de M√°quina (TAM), espec√≠ficamente sobre:\n",
        "\n",
        "- **Reducci√≥n de dimensionalidad** con PCA y UMAP.\n",
        "- **Modelos de clasificaci√≥n supervisada** aplicados al conjunto de datos **USPS**, incluyendo m√©todos cl√°sicos, probabil√≠sticos y de aprendizaje profundo.\n",
        "- **Comparaci√≥n de desempe√±o** entre modelos utilizando m√©tricas, visualizaciones y reportes.\n",
        "\n",
        "## Contenido del Dashboard\n",
        "\n",
        "1. **Visualizaci√≥n del espacio latente**:\n",
        "   - Proyecciones de los datos USPS en 2D usando PCA y UMAP.\n",
        "   - Im√°genes originales superpuestas para an√°lisis visual.\n",
        "   - Exploraci√≥n del efecto del n√∫mero de vecinos en UMAP.\n",
        "\n",
        "2. **Clasificadores evaluados**:\n",
        "   - Modelos tradicionales: SVC, SGD, KNN, Random Forest, entre otros.\n",
        "   - Modelos probabil√≠sticos: Gaussian Naive Bayes, Gaussian Process Classifier.\n",
        "   - Modelos de Deep Learning (CNN).\n",
        "   \n",
        "3. **M√©tricas de desempe√±o**:\n",
        "   - Accuracy, precisi√≥n, sensibilidad, F1-score.\n",
        "   - Curvas ROC por modelo.\n",
        "   - Matrices de confusi√≥n interactivas.\n",
        "\n",
        "4. **Comparaci√≥n interactiva**:\n",
        "   - Selecci√≥n din√°mica de modelos para comparaci√≥n.\n",
        "   - Visualizaci√≥n paralela de resultados.\n",
        "   - Interpretaci√≥n basada en desempe√±o y complejidad del modelo.\n",
        "\n",
        "Este dashboard busca no solo presentar los resultados, sino tambi√©n fomentar la **interpretaci√≥n cr√≠tica de los modelos** y la exploraci√≥n visual de su comportamiento en espacios reducidos de representaci√≥n.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "9qwpo4EGzM9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Instalciones de librerias y Creaci√≥n de las p√°ginas"
      ],
      "metadata": {
        "id": "TNzRUEZOz3yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# CELDA 1: CONFIGURACI√ìN AUTOM√ÅTICA DEL ENTORNO\n",
        "# ==============================================================================\n",
        "# Cualquiera que ejecute esta celda tendr√° el entorno listo.\n",
        "\n",
        "# 1. Instalamos las librer√≠as necesarias en modo silencioso (-q)\n",
        "print(\"‚öôÔ∏è Instalando librer√≠as...\")\n",
        "\n",
        "#Para construir el dashboard interactivo\n",
        "!pip install streamlit -q\n",
        "\n",
        "#Para reducci√≥n de dimensionalidad no lineal\n",
        "!pip install umap-learn -q\n",
        "\n",
        "#Para visualizaciones m√°s interactivas y limpias que matplotlib\n",
        "!pip install plot -q\n",
        "\n",
        "# 2. Creamos la estructura de carpetas necesaria.\n",
        "!mkdir -p pages\n",
        "print(\"üìÅ Estructura de carpetas creada.\")\n",
        "\n",
        "# 3. Descargamos el archivo de datos directamente al lugar correcto.\n",
        "# Usamos el enlace que verificado.\n",
        "DATA_URL = \"https://github.com/Leandro2402-bit/TAM/raw/refs/heads/main/usps.h5\"\n",
        "\n",
        "print(f\"üåç Descargando archivo de datos desde GitHub...\")\n",
        "# Usamos wget para descargar el archivo y guardarlo en la carpeta 'pages'\n",
        "!wget -q -O pages/usps.h5 {DATA_URL}\n",
        "\n",
        "# Verificaci√≥n final\n",
        "import os\n",
        "if os.path.exists('pages/usps.h5'):\n",
        "    print(\"‚úÖ ¬°√âxito! Entorno listo. El archivo usps.h5 ha sido descargado en la carpeta 'pages'.\")\n",
        "else:\n",
        "    print(\"‚ùå Error: La descarga del archivo fall√≥. Verifica la URL.\")"
      ],
      "metadata": {
        "id": "0H2DgpAqVjxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Presentaci√≥n del Dashboard"
      ],
      "metadata": {
        "id": "-C_5eLqpScLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guarda este c√≥digo como un archivo Python llamado \"0_Home.py\"\n",
        "%%writefile 0_Home.py\n",
        "\n",
        "# üìå Importa Streamlit\n",
        "import streamlit as st\n",
        "\n",
        "# ‚öôÔ∏è Configura la p√°gina del dashboard:\n",
        "# - T√≠tulo en la pesta√±a del navegador\n",
        "# - Dise√±o en ancho completo\n",
        "st.set_page_config(page_title=\"Parcial 2 - TAM 2025-1\", layout=\"wide\")\n",
        "\n",
        "# üìù Agrega un bloque de texto con Markdown (para dar formato visual al contenido)\n",
        "st.markdown(\"\"\"\n",
        "# üéì Parcial 2 - Teor√≠a de Aprendizaje de M√°quina 2025-1\n",
        "### üë®‚Äçüè´ Profesor: Andr√©s Marino √Ålvarez Meza, Ph.D.\n",
        "#### üèõ Universidad Nacional de Colombia - Sede Manizales\n",
        "\n",
        "---\n",
        "\n",
        "Bienvenido al dashboard interactivo desarrollado como parte del **Parcial 2 del curso de TAM**.\n",
        "Este entorno ha sido dise√±ado para presentar de forma clara e intuitiva los principales resultados y conceptos trabajados por el grupo.\n",
        "\n",
        "---\n",
        "\n",
        "## üß≠ Navegaci√≥n del Dashboard\n",
        "\n",
        "Este proyecto est√° dividido en **3 m√≥dulos** principales:\n",
        "\n",
        "### üìÑ P√°gina 1: Introducci√≥n Te√≥rica\n",
        "Presenta los fundamentos, f√≥rmulas matem√°ticas y aplicaciones de los modelos usados:\n",
        "PCA, UMAP, GaussianNB, SGDClassifier, Logistic Regression, LDA, KNN, SVC, RandomForest, GPC, Deep Learning.\n",
        "\n",
        "---\n",
        "\n",
        "### üåÄ P√°gina 2: Reducci√≥n de Dimensionalidad\n",
        "Visualizaci√≥n del dataset **USPS** proyectado con **PCA** y **UMAP**, incluyendo ejemplos visuales e interpretaci√≥n de la estructura latente.\n",
        "\n",
        "---\n",
        "\n",
        "### üìä P√°gina 3: Clasificaci√≥n\n",
        "Comparaci√≥n de modelos supervisados aplicados al dataset USPS. Se presentan m√©tricas, curvas ROC y matrices de confusi√≥n.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "üìå Usa el men√∫ de la izquierda para navegar entre los m√≥dulos.\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "6erAG6x8VG07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###P√°gina para el Modulo 1: Introducci√≥n Te√≥rica (Punto a)"
      ],
      "metadata": {
        "id": "FQ8kct8fWh89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guarda este c√≥digo como un archivo Python llamado \"1_Modelos.py\"\n",
        "%%writefile pages/1_Modelos.py\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "# üõ† Configura la p√°gina\n",
        "st.set_page_config(page_title=\"Modelos de Aprendizaje\", layout=\"wide\")\n",
        "\n",
        "# üéØ T√≠tulo de la p√°gina\n",
        "st.title(\"üìÑ Introducci√≥n te√≥rica a los modelos de aprendizaje\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "Selecciona un modelo del men√∫ desplegable para ver su descripci√≥n, formulaci√≥n matem√°tica y aplicaciones.\n",
        "\"\"\")\n",
        "\n",
        "# üîΩ Lista de modelos\n",
        "modelos = [\n",
        "    \"PCA\",\n",
        "    \"UMAP\",\n",
        "    \"GaussianNB\",\n",
        "    \"SGDClassifier\",\n",
        "    \"LogisticRegression\",\n",
        "    \"LinearDiscriminantAnalysis\",\n",
        "    \"KNeighborsClassifier\",\n",
        "    \"SVC\",\n",
        "    \"RandomForestClassifier\",\n",
        "    \"GaussianProcessClassifier\",\n",
        "    \"Deep Learning (CNN)\"\n",
        "]\n",
        "\n",
        "# ‚¨áÔ∏è Selector de modelo\n",
        "modelo = st.selectbox(\"üîé Selecciona un modelo para explorar:\", modelos)\n",
        "\n",
        "# üìò Informaci√≥n de cada modelo\n",
        "if modelo == \"PCA\":\n",
        "    st.subheader(\"üìä PCA - An√°lisis de Componentes Principales\")\n",
        "    st.latex(r'''\n",
        "    \\text{Maximiza la varianza:} \\quad \\max_{\\mathbf{w}} \\ \\mathbf{w}^\\top S \\mathbf{w}\n",
        "    ''')\n",
        "    st.markdown(\"\"\"\n",
        "    - **Objetivo**: Reducir la dimensionalidad de los datos conservando la mayor varianza posible.\n",
        "    - **Aplicaciones**: Compresi√≥n de datos, visualizaci√≥n, preprocesamiento antes de clasificaci√≥n.\n",
        "    \"\"\")\n",
        "\n",
        "elif modelo == \"UMAP\":\n",
        "    st.subheader(\"üåÄ UMAP - Uniform Manifold Approximation and Projection\")\n",
        "    st.latex(r'''\n",
        "    \\text{Minimiza:} \\quad C = \\sum_{(i,j)} w_{ij} \\log \\frac{w_{ij}}{v_{ij}}\n",
        "    ''')\n",
        "    st.markdown(\"\"\"\n",
        "    - **Objetivo**: Aproximar la estructura topol√≥gica de un espacio de alta dimensi√≥n en un espacio de baja dimensi√≥n.\n",
        "    - **Fundamento**: Combina teor√≠a de grafos (simplicial complexes) con medidas de proximidad probabil√≠sticas.\n",
        "    - **Aplicaciones**: Visualizaci√≥n de embeddings, reducci√≥n de dimensionalidad no lineal, exploraci√≥n de datos complejos.\n",
        "    \"\"\")\n",
        "\n",
        "elif modelo == \"GaussianNB\":\n",
        "    st.subheader(\"üìà Gaussian Naive Bayes\")\n",
        "    st.latex(r'''\n",
        "    P(y|x) \\propto P(y) \\prod_{i=1}^{n} P(x_i | y), \\quad P(x_i|y) = \\mathcal{N}(\\mu_{iy}, \\sigma_{iy}^2)\n",
        "    ''')\n",
        "    st.markdown(\"\"\"\n",
        "    - **Supuesto clave**: Independencia entre caracter√≠sticas dado la clase.\n",
        "    - **Aplicaciones**: Texto, clasificaci√≥n r√°pida de datos continuos.\n",
        "    \"\"\")\n",
        "\n",
        "elif modelo == \"SGDClassifier\":\n",
        "    st.subheader(\"‚öôÔ∏è SGDClassifier - Descenso de Gradiente Estoc√°stico\")\n",
        "    st.latex(r'''\n",
        "    \\min_{\\mathbf{w}} \\ \\frac{1}{n} \\sum_{i=1}^{n} \\mathcal{L}(y_i, \\mathbf{w}^\\top x_i) + \\lambda R(\\mathbf{w})\n",
        "    ''')\n",
        "    st.markdown(\"\"\"\n",
        "    - **Usa**: funciones de p√©rdida como hinge (SVM) o log-loss (regresi√≥n log√≠stica).\n",
        "    - **Aplicaciones**: Grandes vol√∫menes de datos en l√≠nea (streaming), NLP.\n",
        "    \"\"\")\n",
        "\n",
        "elif modelo == \"LogisticRegression\":\n",
        "    st.subheader(\"üìâ Regresi√≥n Log√≠stica\")\n",
        "    st.latex(r'''\n",
        "    P(y=1|x) = \\frac{1}{1 + e^{-\\mathbf{w}^\\top x}}, \\quad\n",
        "    \\min_{\\mathbf{w}} \\ -\\sum y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)\n",
        "    ''')\n",
        "    st.markdown(\"\"\"\n",
        "    - **Modelo lineal probabil√≠stico** para clasificaci√≥n binaria o multiclase.\n",
        "    - **Aplicaciones**: Medicina, predicci√≥n de riesgo, an√°lisis de comportamiento.\n",
        "    \"\"\")\n",
        "\n",
        "elif modelo == \"LinearDiscriminantAnalysis\":\n",
        "    st.subheader(\"üìê LDA - An√°lisis Discriminante Lineal\")\n",
        "    st.latex(r'''\n",
        "    \\text{Maximiza:} \\quad J(w) = \\frac{w^\\top S_B w}{w^\\top S_W w}\n",
        "    ''')\n",
        "    st.markdown(\"\"\"\n",
        "    - **Objetivo**: Proyectar los datos para maximizar la separaci√≥n entre clases.\n",
        "    - **Aplicaciones**: Reducci√≥n supervisada de dimensionalidad, clasificaci√≥n.\n",
        "    \"\"\")\n",
        "\n",
        "elif modelo == \"KNeighborsClassifier\":\n",
        "    st.subheader(\"üë• K-Nearest Neighbors (KNN)\")\n",
        "    st.latex(r'''\n",
        "    \\hat{y}(x) = \\text{modo}\\left( \\{ y_i : x_i \\in \\mathcal{N}_k(x) \\} \\right)\n",
        "    ''')\n",
        "    st.markdown(\"\"\"\n",
        "    - **Clasifica** una muestra seg√∫n la mayor√≠a de sus \\( k \\) vecinos m√°s cercanos.\n",
        "    - **No requiere entrenamiento expl√≠cito**, solo distancia y memoria.\n",
        "    - **Aplicaciones**: Reconocimiento de escritura, sistemas de recomendaci√≥n, biometr√≠a.\n",
        "    \"\"\")\n",
        "\n",
        "elif modelo == \"SVC\":\n",
        "    st.subheader(\"‚úÇÔ∏è SVC - Support Vector Classifier\")\n",
        "    st.latex(r'''\n",
        "    \\min_{\\mathbf{w}, b} \\ \\frac{1}{2} \\|\\mathbf{w}\\|^2 + C \\sum \\xi_i \\quad\n",
        "    \\text{s.a.} \\ y_i(\\mathbf{w}^\\top x_i + b) \\geq 1 - \\xi_i\n",
        "    ''')\n",
        "    st.markdown(\"\"\"\n",
        "    - **Encuentra** el hiperplano que maximiza el margen entre clases.\n",
        "    - **Aplicaciones**: Visi√≥n por computador, reconocimiento de texto, bioinform√°tica.\n",
        "    \"\"\")\n",
        "\n",
        "elif modelo == \"RandomForestClassifier\":\n",
        "    st.subheader(\"üå≥ Random Forest Classifier\")\n",
        "    st.latex(r'''\n",
        "    G = 1 - \\sum_{k=1}^{K} p_k^2 \\quad \\text{(√çndice Gini por nodo)}\n",
        "    ''')\n",
        "    st.markdown(\"\"\"\n",
        "    - **Ensamble** de √°rboles de decisi√≥n entrenados sobre subconjuntos aleatorios del dataset (bagging).\n",
        "    - Cada √°rbol minimiza la **impureza** (como el √≠ndice Gini o la entrop√≠a).\n",
        "    - **Aplicaciones**: Clasificaci√≥n robusta en datos ruidosos, biometr√≠a, bioinform√°tica.\n",
        "    \"\"\")\n",
        "\n",
        "elif modelo == \"GaussianProcessClassifier\":\n",
        "    st.subheader(\"üåê Gaussian Process Classifier\")\n",
        "    st.latex(r'''\n",
        "    f(x) \\sim \\mathcal{GP}(0, k(x, x')) \\quad \\Rightarrow \\quad P(y=1|x) = \\sigma(f(x))\n",
        "    ''')\n",
        "    st.markdown(\"\"\"\n",
        "    - **Modelo bayesiano no param√©trico** que define una distribuci√≥n sobre funciones.\n",
        "    - **Aplicaciones**: Clasificaci√≥n con incertidumbre, problemas con pocos datos.\n",
        "    \"\"\")\n",
        "\n",
        "elif modelo == \"Deep Learning (CNN)\":\n",
        "    st.subheader(\"üß† Deep Learning - Redes Convolucionales (CNN)\")\n",
        "    st.latex(r'''\n",
        "    \\min_{\\theta} \\ \\mathcal{L}(y, \\hat{y}) = - \\sum y_i \\log(\\hat{y}_i)\n",
        "    ''')\n",
        "    st.markdown(\"\"\"\n",
        "    - **Aprende filtros convolucionales** para extraer patrones espaciales en im√°genes.\n",
        "    - **Aplicaciones**: Visi√≥n por computador, reconocimiento facial, veh√≠culos aut√≥nomos.\n",
        "    \"\"\")"
      ],
      "metadata": {
        "id": "jQDS73GkWtfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###P√°gina 2: Reducci√≥n de Dimensionalidad (Punto b)"
      ],
      "metadata": {
        "id": "FQ5JEBhvYAvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guarda este c√≥digo como un archivo Python llamado \"pages/2_Reduccion_Dimensionalidad.py\"\n",
        "%%writefile pages/2_Reduccion_Dimensionalidad.py\n",
        "\n",
        "# üìå Importaciones necesarias\n",
        "import streamlit as st\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from pathlib import Path\n",
        "from sklearn.decomposition import PCA\n",
        "import umap\n",
        "\n",
        "# ‚öôÔ∏è Configuraci√≥n de la p√°gina\n",
        "st.set_page_config(page_title=\"Reducci√≥n de Dimensionalidad\", layout=\"wide\")\n",
        "\n",
        "# üìù T√≠tulo y descripci√≥n\n",
        "st.markdown(\"\"\"\n",
        "# üåÄ Reducci√≥n de Dimensionalidad - Dataset USPS\n",
        "### An√°lisis comparativo entre PCA y UMAP\n",
        "\n",
        "Esta p√°gina presenta la proyecci√≥n del dataset USPS en espacios de menor dimensi√≥n usando **PCA** y **UMAP**,\n",
        "incluyendo visualizaciones interactivas y an√°lisis del impacto de hiperpar√°metros.\n",
        "\"\"\")\n",
        "\n",
        "# üîÑ Funci√≥n para cargar datos (con cache para optimizar)\n",
        "@st.cache_data\n",
        "def load_usps_data():\n",
        "    \"\"\"Carga el dataset USPS desde un archivo h5 de forma segura.\"\"\"\n",
        "    try:\n",
        "        script_dir = Path(__file__).parent\n",
        "        path = script_dir / 'usps.h5'\n",
        "        with h5py.File(path, 'r') as hf:\n",
        "            train = hf.get('train')\n",
        "            X_tr, y_tr = train.get('data')[:], train.get('target')[:]\n",
        "            test = hf.get('test')\n",
        "            X_te, y_te = test.get('data')[:], test.get('target')[:]\n",
        "        X = np.concatenate((X_tr, X_te), axis=0)\n",
        "        y = np.concatenate((y_tr, y_te), axis=0)\n",
        "        return X, y\n",
        "    except Exception as e:\n",
        "        st.error(f\"‚ùå Ocurri√≥ un error al cargar los datos: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# üîÑ Funciones de Proyecci√≥n (con cache para optimizar)\n",
        "@st.cache_data\n",
        "def apply_pca(_X):\n",
        "    pca = PCA(n_components=2)\n",
        "    X_pca = pca.fit_transform(_X)\n",
        "    return X_pca, pca.explained_variance_ratio_\n",
        "\n",
        "@st.cache_data\n",
        "def apply_umap(_X, n_neighbors, min_dist):\n",
        "    umap_reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, random_state=42)\n",
        "    X_umap = umap_reducer.fit_transform(_X)\n",
        "    return X_umap\n",
        "\n",
        "# üìä Funci√≥n para crear visualizaci√≥n interactiva\n",
        "def create_interactive_plot(X_2d, y, title, method):\n",
        "    \"\"\"Crea gr√°fico interactivo con Plotly\"\"\"\n",
        "    df = pd.DataFrame(X_2d, columns=['Componente 1', 'Componente 2'])\n",
        "    df['D√≠gito'] = y.astype(str)\n",
        "\n",
        "    fig = px.scatter(\n",
        "        df, x='Componente 1', y='Componente 2', color='D√≠gito',\n",
        "        title=title,\n",
        "        labels={'Componente 1': f'{method} Comp. 1', 'Componente 2': f'{method} Comp. 2'}\n",
        "    )\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "# üéØ Funci√≥n principal\n",
        "def main():\n",
        "    X, y = load_usps_data()\n",
        "    if X is None:\n",
        "        st.stop()\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # --- Pesta√±as para una navegaci√≥n m√°s limpia ---\n",
        "    tab1, tab2 = st.tabs([\"üî¥ An√°lisis PCA\", \"üîµ An√°lisis UMAP\"])\n",
        "\n",
        "    with tab1:\n",
        "        st.header(\"An√°lisis de Componentes Principales (PCA)\")\n",
        "\n",
        "        with st.spinner('Calculando proyecci√≥n PCA... (esto solo ocurre la primera vez)'):\n",
        "            X_pca, explained_variance = apply_pca(X)\n",
        "\n",
        "        col1, col2 = st.columns([3, 1])\n",
        "        with col1:\n",
        "            st.write(\"Visualizaci√≥n de la proyecci√≥n con PCA:\")\n",
        "            create_interactive_plot(X_pca, y, \"Proyecci√≥n del Dataset USPS con PCA\", \"PCA\")\n",
        "        with col2:\n",
        "            st.markdown(\"#### üìä Varianza Explicada\")\n",
        "            # ==> CORREGIDO: Se convierte el valor a un float est√°ndar de Python\n",
        "            total_variance = float(sum(explained_variance))\n",
        "            st.write(f\"**Total:** {total_variance:.2%}\")\n",
        "            st.progress(total_variance)\n",
        "            st.info(f\"Los dos primeros componentes principales capturan el {total_variance:.2%} de la varianza total de los datos.\")\n",
        "\n",
        "    with tab2:\n",
        "        st.header(\"Uniform Manifold Approximation and Projection (UMAP)\")\n",
        "        st.write(\"Explora c√≥mo los hiperpar√°metros de UMAP afectan la estructura latente.\")\n",
        "\n",
        "        subcol1, subcol2 = st.columns(2)\n",
        "        n_neighbors = subcol1.select_slider(\"N√∫mero de vecinos (n_neighbors)\", options=[5, 15, 30, 50, 100], value=15)\n",
        "        min_dist = subcol2.select_slider(\"Distancia m√≠nima (min_dist)\", options=[0.0, 0.1, 0.25, 0.5], value=0.1)\n",
        "\n",
        "        with st.spinner('Calculando proyecci√≥n UMAP... (esto puede tardar un momento)'):\n",
        "            X_umap = apply_umap(X, n_neighbors=n_neighbors, min_dist=min_dist)\n",
        "\n",
        "        st.write(\"Visualizaci√≥n de la proyecci√≥n con UMAP:\")\n",
        "        create_interactive_plot(X_umap, y, f\"Proyecci√≥n con UMAP (Vecinos={n_neighbors})\", \"UMAP\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.header(\"üí° Conclusi√≥n\")\n",
        "    st.write(\"Como se puede observar, **UMAP** genera una separaci√≥n mucho m√°s clara y definida entre las clases (d√≠gitos) en comparaci√≥n con **PCA**. Esto lo convierte en una t√©cnica superior para la visualizaci√≥n de datos y como paso previo para algoritmos de clasificaci√≥n, ya que revela la estructura de 'clusters' de forma m√°s efectiva.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "p_Sirs6saMAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###P√°gina 3: Clasificaci√≥n (Punto c)"
      ],
      "metadata": {
        "id": "Xzg-vvVIYIpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guarda este c√≥digo como un archivo Python llamado \"3_Clasificacion.py\"\n",
        "%%writefile pages/3_Clasificacion.py\n",
        "\n",
        "# üìå Importa las librer√≠as necesarias\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import classification_report, roc_curve, auc\n",
        "from umap import UMAP\n",
        "\n",
        "# Modelos de clasificaci√≥n\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Importar el dataset de d√≠gitos (similar a USPS)\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "# ‚öôÔ∏è Configuraci√≥n inicial de la p√°gina del dashboard\n",
        "st.set_page_config(page_title=\"Resultados de Clasificaci√≥n\", layout=\"wide\")\n",
        "\n",
        "# üìù T√≠tulo y descripci√≥n de la p√°gina\n",
        "st.markdown(\"\"\"\n",
        "# üìä P√°gina 3: Clasificaci√≥n de D√≠gitos\n",
        "En esta secci√≥n se presentan los resultados de aplicar tres modelos de clasificaci√≥n sobre los datos del dataset USPS, previamente proyectados a un espacio de menor dimensi√≥n con UMAP.\n",
        "\n",
        "**Selecciona un modelo del men√∫ desplegable para ver su reporte de desempe√±o y su curva ROC multiclase.**\n",
        "\"\"\")\n",
        "\n",
        "# --- Carga y Preparaci√≥n de Datos ---\n",
        "@st.cache_data\n",
        "def load_and_prepare_data():\n",
        "    \"\"\"\n",
        "    Carga el dataset, aplica UMAP para reducir la dimensionalidad y lo divide\n",
        "    en conjuntos de entrenamiento y prueba.\n",
        "    \"\"\"\n",
        "    digits = load_digits()\n",
        "    X, y = digits.data, digits.target\n",
        "    umap_reducer = UMAP(n_components=2, random_state=42)\n",
        "    X_proj = umap_reducer.fit_transform(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_proj, y, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "    y_train_bin = label_binarize(y_train, classes=np.unique(y))\n",
        "    y_test_bin = label_binarize(y_test, classes=np.unique(y))\n",
        "    n_classes = y_test_bin.shape[1]\n",
        "    return X_train, X_test, y_train, y_test, y_test_bin, n_classes\n",
        "\n",
        "# --- Entrenamiento de Modelos ---\n",
        "@st.cache_resource\n",
        "def train_model(_model, X_train, y_train):\n",
        "    \"\"\"\n",
        "    Entrena un modelo de clasificaci√≥n y lo guarda en cache.\n",
        "    \"\"\"\n",
        "    _model.fit(X_train, y_train)\n",
        "    return _model\n",
        "\n",
        "# --- Visualizaci√≥n de Resultados ---\n",
        "def plot_roc_curve(y_test_bin, y_score, n_classes, model_name):\n",
        "    \"\"\"\n",
        "    Calcula y grafica la curva ROC para un entorno multiclase.\n",
        "    \"\"\"\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    ax.plot([0, 1], [0, 1], 'k--', label='Clasificador Aleatorio')\n",
        "    for i in range(n_classes):\n",
        "        ax.plot(fpr[i], tpr[i], label=f'Clase {i} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "    ax.set_xlabel('Tasa de Falsos Positivos (FPR)')\n",
        "    ax.set_ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
        "    ax.set_title(f'Curva ROC Multiclase - {model_name}')\n",
        "    ax.legend(loc='lower right')\n",
        "    ax.grid(True)\n",
        "    return fig\n",
        "\n",
        "# --- L√≥gica Principal del Dashboard ---\n",
        "X_train, X_test, y_train, y_test, y_test_bin, n_classes = load_and_prepare_data()\n",
        "\n",
        "model_option = st.selectbox(\n",
        "    \"Selecciona el modelo de clasificaci√≥n:\",\n",
        "    (\"K-Nearest Neighbors (KNN)\", \"Regresi√≥n Log√≠stica\", \"Red Neuronal (MLP)\")\n",
        ")\n",
        "\n",
        "if model_option == \"K-Nearest Neighbors (KNN)\":\n",
        "    model = KNeighborsClassifier(n_neighbors=5)\n",
        "    model_name = \"KNN\"\n",
        "elif model_option == \"Regresi√≥n Log√≠stica\":\n",
        "    model = LogisticRegression(max_iter=1000, multi_class='ovr')\n",
        "    model_name = \"Logistic Regression\"\n",
        "else:\n",
        "    model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
        "    model_name = \"MLP\"\n",
        "\n",
        "trained_model = train_model(model, X_train, y_train)\n",
        "y_pred = trained_model.predict(X_test)\n",
        "y_score = trained_model.predict_proba(X_test)\n",
        "\n",
        "st.header(f\"Resultados para {model_name}\")\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    st.subheader(\"Reporte de Clasificaci√≥n\")\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    st.text(report)\n",
        "\n",
        "    # === INICIO DE SECCI√ìN NUEVA: EXPLICACI√ìN DEL REPORTE ===\n",
        "    with st.expander(\"¬øC√≥mo interpretar este reporte?\"):\n",
        "        st.markdown(\"\"\"\n",
        "        El reporte de clasificaci√≥n muestra qu√© tan bien funciona el modelo para cada clase (cada d√≠gito del 0 al 9).\n",
        "\n",
        "        - **Precisi√≥n (Precision):** De todas las veces que el modelo predijo una clase, ¬øqu√© porcentaje fue correcto?\n",
        "          Una alta precisi√≥n indica pocas predicciones incorrectas para esa clase (pocos falsos positivos).\n",
        "\n",
        "        - **Exhaustividad (Recall / Sensibilidad):** De todas las muestras que realmente pertenecen a una clase, ¬øqu√© porcentaje logr√≥ identificar el modelo?\n",
        "          Un alto recall indica que el modelo \"encontr√≥\" la mayor√≠a de las muestras de esa clase (pocos falsos negativos).\n",
        "\n",
        "        - **Puntuaci√≥n F1 (F1-Score):** Es una media arm√≥nica entre precisi√≥n y recall. Un F1-score alto indica un buen balance entre ambas m√©tricas. Es especialmente √∫til cuando hay un desequilibrio entre las clases.\n",
        "\n",
        "        - **Soporte (Support):** Es simplemente el n√∫mero de muestras reales de cada clase en el conjunto de prueba. Ayuda a dar contexto a las otras m√©tricas.\n",
        "\n",
        "        - **Accuracy (Exactitud):** Es el porcentaje total de predicciones correctas sobre el total de muestras.\n",
        "        \"\"\")\n",
        "    # === FIN DE SECCI√ìN NUEVA ===\n",
        "\n",
        "with col2:\n",
        "    st.subheader(\"Curva ROC\")\n",
        "    roc_fig = plot_roc_curve(y_test_bin, y_score, n_classes, model_name)\n",
        "    st.pyplot(roc_fig)\n",
        "\n",
        "    # === INICIO DE SECCI√ìN NUEVA: EXPLICACI√ìN DE LA CURVA ROC ===\n",
        "    with st.expander(\"¬øC√≥mo interpretar esta gr√°fica?\"):\n",
        "        st.markdown(\"\"\"\n",
        "        La **Curva ROC** (Receiver Operating Characteristic) ilustra el rendimiento de un modelo de clasificaci√≥n en todos los umbrales de decisi√≥n.\n",
        "\n",
        "        - **Eje Y (Tasa de Verdaderos Positivos - TPR):** Mide qu√© tan bueno es el modelo para identificar correctamente los casos positivos (similar al Recall). Un valor m√°s alto es mejor.\n",
        "\n",
        "        - **Eje X (Tasa de Falsos Positivos - FPR):** Mide con qu√© frecuencia el modelo clasifica incorrectamente un caso negativo como positivo. Un valor m√°s bajo es mejor.\n",
        "\n",
        "        **Claves para la interpretaci√≥n:**\n",
        "\n",
        "        - **El clasificador ideal** tendr√≠a una curva que sube r√°pidamente hacia la esquina superior izquierda (TPR=1, FPR=0).\n",
        "        - **La l√≠nea punteada diagonal (`k--`)** representa un clasificador que adivina al azar. Cualquier curva por encima de esta l√≠nea es mejor que el azar.\n",
        "        - **Cada l√≠nea de color** representa el rendimiento del modelo para una de las clases (d√≠gitos del 0 al 9) de forma \"uno contra el resto\".\n",
        "        - **AUC (Area Under the Curve):** Es el √°rea bajo la curva. Un valor cercano a 1.0 indica un excelente rendimiento, mientras que un valor cercano a 0.5 corresponde a un clasificador aleatorio.\n",
        "        \"\"\")\n",
        "    # === FIN DE SECCI√ìN NUEVA ==="
      ],
      "metadata": {
        "id": "RZoDg5GTMvNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DESCARGAR Y CONFIGURAR CLOUDFLARED"
      ],
      "metadata": {
        "id": "l8nWUmJYsrqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descarga el ejecutable de Cloudflared (cliente para t√∫neles seguros de Cloudflare)\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "\n",
        "# Otorga permisos de ejecuci√≥n al archivo descargado\n",
        "!chmod +x cloudflared-linux-amd64\n",
        "\n",
        "# Mueve el ejecutable a una ruta del sistema para poder ejecutarlo desde cualquier parte\n",
        "!mv cloudflared-linux-amd64 /usr/local/bin/cloudflared\n",
        "\n",
        "# --- EJECUTAR EL DASHBOARD DE STREAMLIT ---\n",
        "\n",
        "# Lanza Streamlit en segundo plano y guarda los logs en un archivo\n",
        "# Aseg√∫rate de que '0_Home.py' sea el archivo principal de tu dashboard\n",
        "!streamlit run 0_Home.py &>/content/logs.txt &\n",
        "\n",
        "# --- CREAR UN T√öNEL CLOUDFLARE AL PUERTO 8501 ---\n",
        "\n",
        "# Expone el puerto 8501 (por defecto de Streamlit) usando un t√∫nel seguro\n",
        "# El resultado se redirecciona al archivo cloudflared.log\n",
        "!cloudflared tunnel --url http://localhost:8501 > /content/cloudflared.log 2>&1 &\n",
        "\n",
        "# --- ESPERAR QUE SE GENERE LA URL P√öBLICA ---\n",
        "\n",
        "import time\n",
        "time.sleep(5)  # Da tiempo para que Cloudflare genere y escriba la URL en el archivo log\n",
        "\n",
        "# --- EXTRAER LA URL P√öBLICA DESDE EL LOG ---\n",
        "\n",
        "import re\n",
        "found_context = False  # Bandera para detectar si ya estamos en el punto relevante del log\n",
        "\n",
        "# Abre y lee l√≠nea por l√≠nea el archivo de log generado por Cloudflare\n",
        "with open('/content/cloudflared.log') as f:\n",
        "    for line in f:\n",
        "        # Detecta el mensaje que indica que el t√∫nel fue creado exitosamente\n",
        "        if \"Your quick Tunnel has been created\" in line:\n",
        "            found_context = True\n",
        "\n",
        "        # Si estamos en el contexto correcto, busca una URL en la l√≠nea actual\n",
        "        if found_context:\n",
        "            match = re.search(r'https?://\\S+', line)  # Expresi√≥n regular para detectar URL\n",
        "            if match:\n",
        "                url = match.group(0)  # Extrae la URL\n",
        "                print(f'Tu aplicaci√≥n est√° disponible en: {url}')  # Muestra la URL al usuario\n",
        "                break  # Finaliza el bucle despu√©s de encontrar la URL"
      ],
      "metadata": {
        "id": "oz5oFsJkstjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ciclo para finalizar la ejecuci√≥n del Dashboard"
      ],
      "metadata": {
        "id": "dFsdJQTus3dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # Importa el m√≥dulo 'os' para ejecutar comandos del sistema operativo\n",
        "\n",
        "# Solicita al usuario que ingrese una opci√≥n para terminar la ejecuci√≥n\n",
        "res = input(\"Digite (1) para finalizar la ejecuci√≥n del Dashboard: \")\n",
        "\n",
        "# Verifica si el usuario digit√≥ \"1\" (se usa upper() para evitar problemas con min√∫sculas)\n",
        "if res.upper() == \"1\":\n",
        "    os.system(\"pkill streamlit\")  # Ejecuta un comando del sistema que mata el proceso de Streamlit\n",
        "    print(\"El proceso de Streamlit ha sido finalizado.\")  # Muestra un mensaje de confirmaci√≥n"
      ],
      "metadata": {
        "id": "9119ioWXtBT-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}